---
output:
  pdf_document: default
  html_document: default
  word_document: default
date: "2023-11-30"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


# Reading the Data
```{r}
diabetes <- read.csv("D:/Nour/Semester 7/Data Visualization/diabetes.csv")
diabetes = as.data.frame(diabetes)
```


# Histograms
```{r}
par(mfrow = c(2,2))
hist(diabetes$Pregnancies, prob = T, col = "pink", main = "Pregnancies Histogram", xlab="Pregnancies")
lines(density(diabetes$Pregnancies), col = "black", lwd = 2)

hist(diabetes$Glucose , prob = T, col = "lightblue", main = "Glucose Histogram", xlab="Glucose")
lines(density(diabetes$Glucose), col = "black", lwd = 2)

hist(diabetes$BloodPressure , prob = T, col = "lightgreen", main = "Blood Pressure Histogram", xlab="Blood Pressure")
lines(density(diabetes$BloodPressure), col = "black", lwd = 2)

hist(diabetes$SkinThickness , prob = T, col = "purple", main = "Skin Thickness Histogram", xlab="Skin Thickness")
lines(density(diabetes$SkinThickness), col = "black", lwd = 2)

hist(diabetes$Insulin , prob = T, col = "red", main = "Insulin Histogram", xlab="Insulin")
lines(density(diabetes$Insulin), col = "black", lwd = 2)

hist(diabetes$BMI , prob = T, col = "grey", main = "BMI Histogram", xlab="BMI")
lines(density(diabetes$BMI), col = "black", lwd = 2)

hist(diabetes$DiabetesPedigreeFunction , prob = T, col = "brown", main = "Pedigree Function Histogram", xlab="Pedigree Function")
lines(density(diabetes$DiabetesPedigreeFunction), col = "black", lwd = 2)

hist(diabetes$Age , prob = T, col = "yellow", main = "Age Histogram", xlab="Age")
lines(density(diabetes$Age), col = "black", lwd = 2)

```


# Transformed histograms
```{r}
par(mfrow = c(2,2))

hist(log(diabetes$SkinThickness) , prob = T, col = "purple", main = "Log Skin Thickness Histogram", xlab = "Log Skin Thickness")
lines(density(log(diabetes$SkinThickness)), col = "black", lwd = 2, )

hist(log(diabetes$Insulin) , prob = T, col = "red", main = "Log Insulin Histogram", xlab = "Log Insulin")
lines(density(log(diabetes$Insulin)), col = "black", lwd = 2)


hist(log(diabetes$DiabetesPedigreeFunction) , prob = T, col = "brown", main = "Log Pedigree Function Histogram", xlab = "Log Pedigree Function")
lines(density(log(diabetes$DiabetesPedigreeFunction)), col = "black", lwd = 2)

```


# Boxplots
```{r}
# Create box plots for all quantitative variables

par(mfrow=c(2, 2))  # Set up multiple plots per row
for (col in names(diabetes[,-9])) {
  boxplot(diabetes[,-9][[col]], main=col, col="hotpink", border="black", horizontal=TRUE)
}
```



# Piechart
```{r}
# Create a pie chart with percentages
outcome_table <- table(diabetes$Outcome)
colors <- c("hotpink","black")

pie(outcome_table, col = colors, main = "Pie Chart of Outcome Proportion")

# Add percentages
percentages <- round(100 * outcome_table / sum(outcome_table), 1)
labels <- paste(names(outcome_table), "\n", percentages, "%", sep = "")

legend("topright", legend = labels, fill = colors, title = "Outcome", cex = 0.8)
```

#Pairwise scatter matrix
```{r}
pairs(diabetes, upper.panel =NULL, col=4) 

```


# Correlation Matrix
```{r}
library(gplots)

# Assuming 'diabetes' is your dataset
cor_matrix <- cor(diabetes)

# Plotting the heatmap with numbers
heatmap.2(cor_matrix, 
          col = colorRampPalette(c("navy", "white", "firebrick3"))(100),  # Adjust colors as needed
          main = "Correlation Matrix Heatmap",
          trace = "none",  # Remove trace
          density.info = "none",  # Remove density plot
          cexRow = 0.9, cexCol = 0.9,
          margins = c(10, 10),
          key = TRUE, keysize = 1.5, key.title = NA, key.xlab = "Correlation",
          cellnote = round(cor_matrix, 2), notecol = "black", notecex = 0.7)
```


# Dataframe without target variable
```{r}
df <- diabetes[,-9]
head(df, 5)
```


# PCA on correlation matrix
```{r}
corrrrr <- cov(df)
pca <- princomp(as.matrix(df), cor =T)
summary(pca,cutoff=F)
#pca$scores
pca$loadings
```

# Scree Plot
```{r}
plot(1:(length(pca$sdev)),  (pca$sdev)^2, type='b', 
     main="Scree Plot", xlab="Number of Components", ylab="Eigenvalue Size")
abline(h = 1, col = "red", lty = 2)

```


# Biplot for each pair of PC components
```{r}
# Assuming 'pca' is your PCA object
biplot(pca, choices = c(1, 2), main = "Biplot PC1 and PC2")
biplot(pca, choices = c(2, 3), main = "Biplot PC2 and PC3")
biplot(pca, choices = c(1, 3), main = "Biplot PC1 and PC3")


```


# 3D Plot
```{r}
pc1 <- pca$scores[, 1]
pc2 <- pca$scores[, 2]
pc3 <- pca$scores[, 3]
 
# Extract variable loadings (vector loadings)
loadings <- pca$rotation
 
# Create a vector of colors based on the 'diagnosis' variable
colors <- ifelse(diabetes$Outcome == 1, "lightblue", "navy")

legend_plot <- plot(1, type = "n", axes = FALSE, xlab = "", ylab = "")
points(1, 1, pch = 16, col = "lightblue", cex = 2, legend = "Outcome = 1")
points(1, 0, pch = 16, col = "navy", cex = 2, legend = "Outcome = 0")

library(scatterplot3d)
# Plot 3D scatterplot with principal components and loadings
scatterplot3d(x = pc1, y = pc2, z = pc3, main = "3D Principal Components with Loadings",
              xlab = "PC1", ylab = "PC2", zlab = "PC3",
              color = colors, pch = 16)

legend("topright", legend = c("Diabetes = 1", "No Diabetes = 0"), pch = 16, col = c("lightblue", "navy"), cex = 0.8)

```

```{r}
library(MASS)
library(caret)
```



```{r}
chisplot <- function(x) {
  if (!is.matrix(x)) stop("x is not a matrix")
  
  ### determine dimensions
  n <- nrow(x)
  p <- ncol(x)
  #
  xbar <- apply(x, 2, mean)
  S <- var(x)
  S <- solve(S,tol=1e-40)
  index <- (1:n)/(n+1)
  #
  xcent <- t(t(x) - xbar)
  di <- apply(xcent, 1, function(x,S) x %*% S %*% x,S)
  #
  quant <- qchisq(index,p)
  plot(quant, sort(di), ylab = "Ordered distances",
       xlab = "Chi-square quantile", lwd=2,pch=1)
  
}

```


# Testing for normality using Chi-square quantile plot
```{r}

par(mfrow=c(1,2))
chisplot(as.matrix(diabetes[diabetes$Outcome==1,-9]))
abline(0,1,col=2)
chisplot(as.matrix(diabetes[diabetes$Outcome==0,-9]))
abline(0,1,col=2)
```


# Tesing for Equal Covariance Matrices using BoxM
```{r}
library(biotools)  
boxM(diabetes[,-9],diabetes$Outcome) 
```


# Normalizing the data before LDA
```{r}
normalized_data <- scale(diabetes[,-9])
normalized_data <- as.data.frame(normalized_data)
normalized_data['Outcome'] = diabetes$Outcome
```


# LDA using Default priors
```{r}
train_index <- sample(seq_len(nrow(normalized_data)), size = 0.8 * nrow(normalized_data))
train_data <- normalized_data[train_index, ]
test_data <- normalized_data[-train_index, ]
set.seed(0)

lda_model <- lda(Outcome ~ ., data = train_data)

# Make predictions on the testing data
predictions <- predict(lda_model, newdata = test_data)

# Confusion matrix (for classification problems)
conf_matrix <- table(predictions$class, test_data$Outcome)
print(conf_matrix)

accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
cat("Overall Accuracy:", accuracy, "\n")
```


# LDA using Equal priors
```{r}
train_index <- sample(seq_len(nrow(normalized_data)), size = 0.8 * nrow(normalized_data))
train_data <- normalized_data[train_index, ]
test_data <- normalized_data[-train_index, ]
set.seed(0)

# Perform LDA on the training data
lda_model <- lda(Outcome ~ . , data = train_data, prior = c(0.5,0.5))

# Make predictions on the testing data
predictions <- predict(lda_model, newdata = test_data)

# Confusion matrix (for classification problems)
conf_matrix <- table(predictions$class, test_data$Outcome)
print(conf_matrix)

accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
cat("Overall Accuracy:", accuracy, "\n")
```


# QDA using Equal priors

```{r}
train_index <- sample(seq_len(nrow(normalized_data)), size = 0.8 * nrow(normalized_data))
train_data <- normalized_data[train_index, ]
test_data <- normalized_data[-train_index, ]
set.seed(0)
disquad <- qda(Outcome ~ ., data = train_data, prior = c(0.5,0.5))
disquad

```



```{r}
# Make predictions on the testing data
predictions <- predict(disquad, newdata = test_data)

# Confusion matrix (for classification problems)
conf_matrix <- table(predictions$class, test_data$Outcome)
print(conf_matrix)

accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
cat("Overall Accuracy:", accuracy, "\n")
```


# QDA using Default priors
```{r}
train_index <- sample(seq_len(nrow(normalized_data)), size = 0.8 * nrow(normalized_data))
train_data <- normalized_data[train_index, ]
test_data <- normalized_data[-train_index, ]
set.seed(0)

disquad2 <- qda(Outcome ~ ., data = train_data)
disquad2

```


```{r}
# Make predictions on the testing data
predictions <- predict(disquad2, newdata = test_data)

# Confusion matrix (for classification problems)
conf_matrix <- table(predictions$class, test_data$Outcome)
print(conf_matrix)

accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
cat("Overall Accuracy:", accuracy, "\n")
```



